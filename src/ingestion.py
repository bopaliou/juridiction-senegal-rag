from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader,PyPDFLoader,WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from pathlib import Path
import shutil

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

load_dotenv()

# Resolve data paths relative to the project root (one level up from `src/`)
BASE_DIR = Path(__file__).resolve().parents[1]
DATA_PATH = BASE_DIR / "data"
DATA_DB_PATH = BASE_DIR / "data" / "chroma_db"
URL_CONSTITUTION = "https://conseilconstitutionnel.sn/la-constitution/"
URL_CODE_DES_COLLECTIVITES_LOCALES ="https://primature.sn/publications/lois-et-reglements/code-des-collectivites-locales"
URL_CODE_DE_AVIATION_CIVILE="https://primature.sn/publications/lois-et-reglements/code-de-laviation-civile"
URL_MISE_A_JOUR_CONSTITUTION="https://primature.sn/publications/lois-et-reglements/mises-jour-de-la-constitution"

def ingest_documents():
    #1. Chargtement recursif des documents
    print(f"Chargement des documents depuis : {DATA_PATH}")

    if not DATA_PATH.exists():
        raise FileNotFoundError(
            f"Data directory not found: '{DATA_PATH}'.\nExpected 'data' directory at project root ({BASE_DIR})."
        )

    loader_pdf = DirectoryLoader(
        path=str(DATA_PATH),
        glob="**/*.pdf",
        loader_cls=PyPDFLoader,
        show_progress=True,
    )
    documents_pdf = loader_pdf.load()
    print(f"{len(documents_pdf)} documents charg√©s.")
    
    loader_web = WebBaseLoader(
        web_path=[URL_CONSTITUTION,URL_CODE_DES_COLLECTIVITES_LOCALES,URL_CODE_DE_AVIATION_CIVILE,URL_MISE_A_JOUR_CONSTITUTION],
        show_progress=True,
    )
    documents_web = loader_web.load()
    print(f"{len(documents_web)} documents charg√©s.")
    
    documents = documents_pdf + documents_web
    print(f"{len(documents)} documents charg√©s.")
    
    #Decoupage(chunking) des documents
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
    
    )
    chunks = text_splitter.split_documents(documents)
    print(f"{len(chunks)} chunks cr√©√©s apr√®s d√©coupage.")
    
    # Supprimer l'ancienne base de donn√©es si elle existe pour √©viter les conflits
    if DATA_DB_PATH.exists():
        print(f"‚ö†Ô∏è  Suppression de l'ancienne base de donn√©es √† : {DATA_DB_PATH}")
        shutil.rmtree(DATA_DB_PATH)
    
    # Cr√©er le r√©pertoire s'il n'existe pas
    DATA_DB_PATH.mkdir(parents=True, exist_ok=True)
    
    #vectorisation et stockage dans la base de donn√©es Chroma
    print("üîÑ Cr√©ation des embeddings et stockage dans Chroma...")
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    
    # Cr√©er la base de donn√©es Chroma avec tous les chunks
    # Utiliser collection_name pour √©viter les conflits
    print(f"üì¶ Stockage de {len(chunks)} chunks dans Chroma...")
    
    # V√©rifier que les chunks contiennent du contenu
    valid_chunks = [chunk for chunk in chunks if chunk.page_content and len(chunk.page_content.strip()) > 0]
    print(f"üìä {len(valid_chunks)} chunks valides sur {len(chunks)} total")
    
    if len(valid_chunks) == 0:
        print("‚ùå ERREUR: Aucun chunk valide √† stocker!")
        return
    
    # Cr√©er la base de donn√©es Chroma
    print("üîÑ Cr√©ation de la base de donn√©es Chroma...")
    print(f"   üìÅ R√©pertoire: {DATA_DB_PATH}")
    print(f"   üì¶ Nombre de documents: {len(valid_chunks)}")
    print("   ‚è≥ Cela peut prendre plusieurs minutes...")
    
    # Cr√©er la base avec from_documents (cela peut prendre du temps)
    try:
        db = Chroma.from_documents(
            documents=valid_chunks,
            embedding=embedding_model,
            persist_directory=str(DATA_DB_PATH),
            collection_name="juridiction_senegal",  # Nom explicite pour la collection
        )
        print("‚úÖ Base de donn√©es Chroma cr√©√©e.")
    except Exception as e:
        print(f"‚ùå ERREUR lors de la cr√©ation: {e}")
        import traceback
        traceback.print_exc()
        return
    
    print("üîÑ V√©rification de la persistance...")
    
    # V√©rifier imm√©diatement que les donn√©es ont √©t√© stock√©es
    try:
        # Attendre un peu pour que la persistance se termine
        import time
        print("   ‚è≥ Attente de 2 secondes pour la persistance...")
        time.sleep(2)
        
        # V√©rifier les fichiers cr√©√©s
        if DATA_DB_PATH.exists():
            files = list(DATA_DB_PATH.iterdir())
            print(f"   üìÇ Fichiers cr√©√©s: {len(files)}")
            total_size = 0
            for f in files[:10]:  # Afficher les 10 premiers fichiers
                if f.is_file():
                    size = f.stat().st_size
                    total_size += size
                    print(f"      - {f.name} ({size:,} bytes)")
            print(f"   üíæ Taille totale: {total_size:,} bytes")
        
        # Recharger la base pour v√©rifier
        print("üîç Rechargement de la base de donn√©es...")
        db_check = Chroma(
            persist_directory=str(DATA_DB_PATH),
            embedding_function=embedding_model,
            collection_name="juridiction_senegal"
        )
        
        # V√©rifier le nombre de documents
        collection = db_check._collection
        count = collection.count() if collection else 0
        print(f"‚úÖ Base de donn√©es Chroma cr√©√©e √† : {DATA_DB_PATH}")
        print(f"‚úÖ {count} documents stock√©s dans la base de donn√©es.")
        
        if count == 0:
            print("‚ùå ERREUR: Aucun document n'a √©t√© stock√©!")
            print("üí° Tentative de diagnostic...")
            
            # V√©rifier si le r√©pertoire existe et contient des fichiers
            if DATA_DB_PATH.exists():
                files = list(DATA_DB_PATH.iterdir())
                print(f"   üìÇ Fichiers dans le r√©pertoire: {len(files)}")
                for f in files[:5]:  # Afficher les 5 premiers fichiers
                    print(f"      - {f.name}")
            
            # Essayer de voir les collections disponibles avec chromadb directement
            try:
                import chromadb
                client = chromadb.PersistentClient(path=str(DATA_DB_PATH))
                collections = client.list_collections()
                print(f"   üìö Collections trouv√©es: {len(collections)}")
                for col in collections:
                    col_count = col.count()
                    print(f"      - {col.name}: {col_count} documents")
                    if col_count > 0:
                        print(f"         ‚úÖ Collection '{col.name}' contient {col_count} documents!")
            except Exception as e2:
                print(f"   ‚ö†Ô∏è  Erreur lors de la v√©rification des collections: {e2}")
                import traceback
                traceback.print_exc()
            
            return
        
        # Test de r√©cup√©ration pour confirmer
        print("üîç Test de r√©cup√©ration...")
        test_results = db_check.similarity_search("test", k=1)
        if test_results:
            print(f"‚úÖ Test de r√©cup√©ration r√©ussi: {len(test_results)} document(s) trouv√©(s)")
            print(f"   üìÑ Premier document: {test_results[0].page_content[:100]}...")
        else:
            print("‚ö†Ô∏è  Avertissement: Test de r√©cup√©ration n'a retourn√© aucun r√©sultat")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur lors de la v√©rification : {e}")
        import traceback
        traceback.print_exc()
        print(f"‚úÖ Base de donn√©es Chroma cr√©√©e √† : {DATA_DB_PATH}")
    
if __name__ == "__main__":
    print(BASE_DIR)
    ingest_documents()  